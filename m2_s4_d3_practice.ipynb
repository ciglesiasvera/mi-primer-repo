{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cf784a",
   "metadata": {},
   "source": [
    "Ejercicio: Diseño de arquitectura Big Data para análisis de e-commerce\n",
    "\n",
    "Análisis de requisitos y patrones de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05fecda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTIMACIONES DE VOLUMEN - E-COMMERCE MENSUAL\n",
      "==================================================\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "PATRONES DE CONSULTA IDENTIFICADOS\n",
      "========================================\n",
      "\n",
      "TIEMPO_REAL:\n",
      "\n",
      "BATCH_DIARIO:\n",
      "\n",
      "BATCH_SEMANAL:\n",
      " • Tendencias de productos\n",
      " • Segmentación de clientes\n",
      " • Análisis de campañas de marketing\n"
     ]
    }
   ],
   "source": [
    "# Análisis de volúmenes y patrones para e-commerce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Estimación de volúmenes para plataforma e-commerce\n",
    "estimaciones_mensuales = {\n",
    "    'eventos_usuario': 50000000,    # 50M eventos (clicks, views, etc.)\n",
    "    'ordenes': 1000000,             # 1M órdenes\n",
    "    'productos': 100000,            # 100K productos\n",
    "    'clientes_activos': 5000000,    # 5M clientes activos\n",
    "    'reviews': 500000,              # 500K reviews\n",
    "    'logs_sistema': 100000000       # 100M logs diarios\n",
    "}\n",
    "\n",
    "print(\"ESTIMACIONES DE VOLUMEN - E-COMMERCE MENSUAL\")\n",
    "print(\"=\" * 50)\n",
    "for componente, volumen in estimaciones_mensuales.items():\n",
    "    print(\"25\")\n",
    "\n",
    "# Patrones de consulta identificados\n",
    "patrones_consulta = {\n",
    "    'tiempo_real': [\n",
    "        '¿Cuántos usuarios activos ahora?',\n",
    "        '¿Cuál es la conversión actual?',\n",
    "        '¿Hay anomalías en ventas?'\n",
    "    ],\n",
    "    'batch_diario': [\n",
    "        'Reportes de ventas por categoría',\n",
    "        'Análisis de comportamiento de cliente',\n",
    "        'Optimización de inventario'\n",
    "    ],\n",
    "    'batch_semanal': [\n",
    "        'Tendencias de productos',\n",
    "        'Segmentación de clientes',\n",
    "        'Análisis de campañas de marketing'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"PATRONES DE CONSULTA IDENTIFICADOS\") \n",
    "print(\"=\" * 40) \n",
    "for frecuencia, consultas in patrones_consulta.items(): \n",
    "    print(f\"\\n{frecuencia.upper()}:\") \n",
    "for consulta in consultas: \n",
    "    print(f\" • {consulta}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8477e2",
   "metadata": {},
   "source": [
    "Diseño de arquitectura híbrida Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4cbd7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARQUITECTURA LAMBDA PROPUESTA\n",
      "===================================\n",
      "\n",
      "CAPA STREAMING:\n",
      "  Tecnologías: Apache Kafka, Apache Flink, Redis\n",
      "  Latencia: milisegundos-segundos\n",
      "  Casos de uso:\n",
      "    • Monitoreo en tiempo real de ventas\n",
      "    • Detección de fraudes\n",
      "    • Personalización de recomendaciones\n",
      "    • Alertas de inventario bajo\n",
      "\n",
      "CAPA BATCH:\n",
      "  Tecnologías: Apache Spark, Hadoop MapReduce, Apache Airflow\n",
      "  Latencia: horas-días\n",
      "  Casos de uso:\n",
      "    • Reportes de performance mensual\n",
      "    • Modelos de machine learning\n",
      "    • Análisis de cohortes de clientes\n",
      "    • Optimización de precios\n",
      "\n",
      "CAPA SERVING:\n",
      "  Tecnologías: Apache Druid, ClickHouse, Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "# Arquitectura Lambda para e-commerce\n",
    "arquitectura_lambda = {\n",
    "    'capa_streaming': {\n",
    "        'tecnologias': ['Apache Kafka', 'Apache Flink', 'Redis'],\n",
    "        'casos_uso': [\n",
    "            'Monitoreo en tiempo real de ventas',\n",
    "            'Detección de fraudes',\n",
    "            'Personalización de recomendaciones',\n",
    "            'Alertas de inventario bajo'\n",
    "        ],\n",
    "        'latencia': 'milisegundos-segundos',\n",
    "        'datos': 'eventos individuales'\n",
    "    },\n",
    "    'capa_batch': {\n",
    "        'tecnologias': ['Apache Spark', 'Hadoop MapReduce', 'Apache Airflow'],\n",
    "        'casos_uso': [\n",
    "            'Reportes de performance mensual',\n",
    "            'Modelos de machine learning',\n",
    "            'Análisis de cohortes de clientes',\n",
    "            'Optimización de precios'\n",
    "        ],\n",
    "        'latencia': 'horas-días',\n",
    "        'datos': 'datasets completos'\n",
    "    },\n",
    "    'capa_serving': {\n",
    "        'tecnologias': ['Apache Druid', 'ClickHouse', 'Elasticsearch'],\n",
    "        'funciones': [\n",
    "            'Unificar resultados batch + streaming',\n",
    "            'Servir consultas analíticas rápidas',\n",
    "            'Dashboards en tiempo real',\n",
    "            'APIs para aplicaciones'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ARQUITECTURA LAMBDA PROPUESTA\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "for capa, detalles in arquitectura_lambda.items():\n",
    "    print(f\"\\n{capa.upper().replace('_', ' ')}:\")\n",
    "    print(f\"  Tecnologías: {', '.join(detalles['tecnologias'])}\")\n",
    "    if 'latencia' in detalles:\n",
    "        print(f\"  Latencia: {detalles['latencia']}\")\n",
    "    if 'casos_uso' in detalles:\n",
    "        print(\"  Casos de uso:\")\n",
    "        for caso in detalles['casos_uso']:\n",
    "            print(f\"    • {caso}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62035436",
   "metadata": {},
   "source": [
    "Implementación de pipeline de procesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce49917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESTRATEGIA DE ESCALABILIDAD\n",
      "==============================\n",
      "Volumen actual: 10TB datos/mes\n",
      "Proyección 2 años: 100TB datos/mes\n",
      "Estrategias:\n",
      " • Auto-scaling de clusters Spark/Flink\n",
      " • Particionamiento horizontal adicional\n",
      " • Compresión columnar avanzada\n",
      " • Cache distribuido (Redis Cluster)\n",
      " • CDN para datos estáticos\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de procesamiento para arquitectura Lambda\n",
    "def lambda_pipeline_arquitecture():\n",
    "    \"\"\"\n",
    "    Arquitectura Lambda simplificada para e-commerce\n",
    "    \"\"\"\n",
    "    \n",
    "    # CAPA DE STREAMING (velocidad)\n",
    "    def capa_streaming():\n",
    "        \"\"\"Procesamiento en tiempo real\"\"\"\n",
    "        eventos_stream = kafka_consumer.consume('user_events')\n",
    "        \n",
    "        # Procesamiento con Flink\n",
    "        eventos_procesados = eventos_stream \\\n",
    "            .filter(lambda x: x['event_type'] == 'purchase') \\\n",
    "            .key_by(lambda x: x['user_id']) \\\n",
    "            .window(TumblingEventTimeWindows.of(Time.minutes(5))) \\\n",
    "            .aggregate(AggregationFunction())\n",
    "        \n",
    "        # Resultados a Redis para consultas rápidas\n",
    "        eventos_procesados.addSink(redis_sink)\n",
    "        \n",
    "        # También a storage duradero para batch layer\n",
    "        eventos_procesados.addSink(s3_sink)\n",
    "    \n",
    "    # CAPA DE BATCH (precisión)\n",
    "    def capa_batch():\n",
    "        \"\"\"Procesamiento completo y preciso\"\"\"\n",
    "        # Leer todos los datos históricos\n",
    "        datos_completos = spark.read.parquet('s3://data-lake/events/')\n",
    "        \n",
    "        # Procesamiento completo con Spark\n",
    "        metricas_batch = datos_completos \\\n",
    "            .groupBy('fecha', 'categoria') \\\n",
    "            .agg(\n",
    "                sum('revenue').alias('ventas_total'),\n",
    "                countDistinct('user_id').alias('clientes_unicos'),\n",
    "                (sum('purchases') / countDistinct('user_id')).alias('conversion_rate')\n",
    "            )\n",
    "        \n",
    "        # Guardar resultados batch\n",
    "        metricas_batch.write.mode('overwrite').parquet('s3://data-lake/batch-metrics/')\n",
    "    \n",
    "    # CAPA DE SERVING (unificación)\n",
    "    def capa_serving():\n",
    "        \"\"\"Unificar y servir resultados\"\"\"\n",
    "        # Combinar resultados streaming + batch\n",
    "        resultados_streaming = redis_cluster.get_recent_metrics()\n",
    "        resultados_batch = spark.read.parquet('s3://data-lake/batch-metrics/')\n",
    "        \n",
    "        # Unificar en ClickHouse para consultas analíticas\n",
    "        resultados_combinados = merge_results(resultados_streaming, resultados_batch)\n",
    "        clickhouse_client.insert('metricas_unificadas', resultados_combinados)\n",
    "    \n",
    "    return {\n",
    "        'streaming': capa_streaming,\n",
    "        'batch': capa_batch, \n",
    "        'serving': capa_serving\n",
    "    }\n",
    "\n",
    "# Demostración de escalabilidad\n",
    "escalabilidad = {\n",
    "    'volumen_actual': '10TB datos/mes',\n",
    "    'proyeccion_2_años': '100TB datos/mes',\n",
    "    'estrategias_escalabilidad': [\n",
    "        'Auto-scaling de clusters Spark/Flink',\n",
    "        'Particionamiento horizontal adicional',\n",
    "        'Compresión columnar avanzada',\n",
    "        'Cache distribuido (Redis Cluster)',\n",
    "        'CDN para datos estáticos'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"ESTRATEGIA DE ESCALABILIDAD\") \n",
    "print(\"=\" * 30) \n",
    "print(f\"Volumen actual: {escalabilidad['volumen_actual']}\") \n",
    "print(f\"Proyección 2 años: {escalabilidad['proyeccion_2_años']}\") \n",
    "print(\"Estrategias:\") \n",
    "for estrategia in escalabilidad['estrategias_escalabilidad']: \n",
    "    print(f\" • {estrategia}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947771c3",
   "metadata": {},
   "source": [
    "Verificación: Explica cómo la arquitectura Lambda resuelve el trade-off entre velocidad (streaming) y precisión (batch), y describe escenarios donde elegirías Kappa sobre Lambda para simplificar la arquitectura.\n",
    "\n",
    "La arquitectura Lambda separa el procesamiento en streaming para obtener resultados rápidos con baja latencia y en batch para recalcular métricas completas y precisas sobre datos históricos. Así combina velocidad inmediata con exactitud a largo plazo.\n",
    "\n",
    "Se elige Kappa cuando todo el procesamiento puede hacerse como streaming, reprocesando eventos desde Kafka, y se busca simplificar la arquitectura evitando mantener pipelines batch separados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analisis_datos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
